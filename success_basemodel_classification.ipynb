{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recipe_Name</th>\n",
       "      <th>Recipe_Ingredients</th>\n",
       "      <th>Cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bunny chow</td>\n",
       "      <td>2 tbsp vegetable oil ½ tsp cumin seeds ½ tsp f...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jollof rice with fried plantains</td>\n",
       "      <td>1 tbsp olive or vegetable oil 2 large onions, ...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jollof rice</td>\n",
       "      <td>400ml/14fl oz passata 3 tbsp tomato purée 2 fr...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suya fillet burger with sweet potato cubes and...</td>\n",
       "      <td>4g smoked paprika  2g cayenne pepper 6g ginger...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jollof rice with chicken</td>\n",
       "      <td>300g/10½oz basmati rice 1 tbsp vegetable oil 8...</td>\n",
       "      <td>african</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Recipe_Name  \\\n",
       "0                                         Bunny chow   \n",
       "1                   Jollof rice with fried plantains   \n",
       "2                                        Jollof rice   \n",
       "3  Suya fillet burger with sweet potato cubes and...   \n",
       "4                          Jollof rice with chicken    \n",
       "\n",
       "                                  Recipe_Ingredients  Cuisine  \n",
       "0  2 tbsp vegetable oil ½ tsp cumin seeds ½ tsp f...  african  \n",
       "1  1 tbsp olive or vegetable oil 2 large onions, ...  african  \n",
       "2  400ml/14fl oz passata 3 tbsp tomato purée 2 fr...  african  \n",
       "3  4g smoked paprika  2g cayenne pepper 6g ginger...  african  \n",
       "4  300g/10½oz basmati rice 1 tbsp vegetable oil 8...  african  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('all_recipe_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop_duplicates(subset='Recipe_Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recipe_Name</th>\n",
       "      <th>Recipe_Ingredients</th>\n",
       "      <th>Cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>475</td>\n",
       "      <td>475</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>475</td>\n",
       "      <td>475</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Saag gosht (lamb and spinach curry) with chapatis</td>\n",
       "      <td>740g/1lb 10oz lamb fillet, trimmed and cubed 1...</td>\n",
       "      <td>mexican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Recipe_Name  \\\n",
       "count                                                 475   \n",
       "unique                                                475   \n",
       "top     Saag gosht (lamb and spinach curry) with chapatis   \n",
       "freq                                                    1   \n",
       "\n",
       "                                       Recipe_Ingredients  Cuisine  \n",
       "count                                                 475      475  \n",
       "unique                                                475       21  \n",
       "top     740g/1lb 10oz lamb fillet, trimmed and cubed 1...  mexican  \n",
       "freq                                                    1       24  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df)) < 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df[msk]\n",
    "len(train)\n",
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[~msk]\n",
    "len(test)\n",
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(382, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(382,)\n",
      "(382,)\n",
      "(93,)\n",
      "(93,)\n"
     ]
    }
   ],
   "source": [
    "data_train= train['Recipe_Ingredients']\n",
    "target_train= train['Cuisine']\n",
    "data_test= test['Recipe_Ingredients']\n",
    "target_test= test['Cuisine']\n",
    "print(data_train.shape)\n",
    "print(target_train.shape)\n",
    "print(data_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train=re.sub(\"[^'?a-z\\,?]\", ' ', train['Recipe_Ingredients'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/Iffy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords_list = stopwords.words('english')+ list(string.punctuation)\n",
    "stopwords_list+= [\"''\", '\"\"', '...', '``']\n",
    "stopwords_list+= ['tbsp', 'tsp', 'cup', 'cups']\n",
    "# regex = r\"[^'?a-z\\,?]\"\n",
    "# stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_article(article):\n",
    "    tokens = nltk.word_tokenize(article)\n",
    "    stopwords_removed = [token.lower() for token in tokens if token not in stopwords_list]\n",
    "    return stopwords_removed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('punkt')\n",
    "processed_train =  list(map(process_article, data_train))\n",
    "processed_test= list(map(process_article, data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned train:  ['2', 'vegetable', 'oil', '½', 'cumin', 'seeds', '½', 'fennel', 'seeds', '2.5cm/1in', 'piece', 'cinnamon', 'stick', '2', 'green', 'cardamom', 'pods', '1', 'star', 'anise', '1', 'bay', 'leaf', '1', 'onion', 'finely', 'chopped', '2', 'south', 'african', 'curry', 'powder', '2', 'tomatoes', 'chopped', '1kg/2lb', '2oz', 'boneless', 'leg', 'lamb', 'cut', '1.5cm/½in', 'dices', '1', 'finely', 'chopped', 'fresh', 'ginger', '1', 'finely', 'chopped', 'garlic', '10-12', 'curry', 'leaves', '2', 'large', 'potatoes', 'cut', 'cubes', 'size', 'meat', 'salt', '2', 'finely', 'chopped', 'coriander', 'leaves', '2', 'lime', 'juice', '2', 'loaves', 'crusty', 'white', 'bread', 'unsliced', 'cut', 'across', 'half', 'middle', 'crumbs', 'removed', 'coriander', 'cress', 'sprigs', 'garnish']\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "cleaned test:  ['butter', 'greasing', '400ml/14fl', 'oz', 'full-fat', 'milk', '50g/1¾oz', 'fresh', 'white', 'breadcrumbs', '4', 'large', 'free-range', 'eggs', 'beaten', '1', 'olive', 'oil', '1kg/2lb', '4oz', 'lamb', 'mince', '2', 'onions', 'finely', 'chopped', '1', 'bay', 'leaf', '2', 'garlic', 'cloves', 'crushed', '2', 'madras', 'curry', 'paste', '250ml/9fl', 'oz', 'lamb', 'stock', '2', 'worcestershire', 'sauce', '2', 'mango', 'chutney', '50g/1¾oz', 'raisins', '50g/1¾oz', 'dried', 'apricots', 'chopped', '1', 'cider', 'vinegar']\n"
     ]
    }
   ],
   "source": [
    "print('cleaned train: ', processed_train[0])\n",
    "print('----'*28)\n",
    "print('cleaned test: ', processed_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21056"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern= r\"[a-z]+\"\n",
    "p= re.compile(pattern)\n",
    "ptrain= p.findall(str(processed_train))\n",
    "len(ptrain)\n",
    "# print(ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5023"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptest= p.findall(str(processed_test))\n",
    "len(ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_concat_train = []\n",
    "for pd in processed_train:\n",
    "    articles_concat_train += pd\n",
    "articles_concat_test = []\n",
    "for pd in processed_test:\n",
    "    articles_concat_test += pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_freqdist_train = FreqDist(articles_concat_train)\n",
    "# articles_freqdist_train.most_common(200)\n",
    "articles_freqdist_test = FreqDist(articles_concat_test)\n",
    "# articles_freqdist_test.most_common(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21056, 1437)\n",
      "(5023, 1437)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_ptrain = vectorizer.fit_transform(ptrain)\n",
    "tf_idf_ptest = vectorizer.transform(ptest)\n",
    "print(tf_idf_ptrain.shape)\n",
    "print(tf_idf_ptest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 0.9395896656534954\n",
      "Percentage of columns containing 0: 0.9993461449786684\n"
     ]
    }
   ],
   "source": [
    "non_zero_cols = tf_idf_ptrain.nnz / float(tf_idf_ptrain.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_cols))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_cols / float(tf_idf_ptrain.shape[1]))\n",
    "print('Percentage of columns containing 0: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes and Random Forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier.fit(tf_idf_ptrain, ptrain)\n",
    "nb_train_preds = nb_classifier.predict(tf_idf_ptrain)\n",
    "nb_test_preds = nb_classifier.predict(tf_idf_ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier.fit(tf_idf_ptrain, ptrain)\n",
    "rf_train_preds = rf_classifier.predict(tf_idf_ptrain)\n",
    "rf_test_preds = rf_classifier.predict(tf_idf_ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "Training Accuracy: 0.6398 \t\t Testing Accuracy: 0.6472\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Random Forest\n",
      "Training Accuracy: 0.9953 \t\t Testing Accuracy: 0.9685\n"
     ]
    }
   ],
   "source": [
    "nb_train_score = accuracy_score(ptrain, nb_train_preds)\n",
    "nb_test_score = accuracy_score(ptest, nb_test_preds)\n",
    "rf_train_score = accuracy_score(ptrain, rf_train_preds)\n",
    "rf_test_score = accuracy_score(ptest, rf_test_preds)\n",
    "\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(nb_train_score, nb_test_score))\n",
    "print(\"\")\n",
    "print('-'*70)\n",
    "print(\"\")\n",
    "print('Random Forest')\n",
    "print(\"Training Accuracy: {:.4} \\t\\t Testing Accuracy: {:.4}\".format(rf_train_score, rf_test_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as KNC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier= KNC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier.fit(tf_idf_ptrain, ptrain)\n",
    "test_preds= knn_classifier.predict(tf_idf_ptest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_knn_metrics(labels, preds, avg):\n",
    "    print(\"Precision Score: {}\".format(precision_score(labels, preds, average=avg)))\n",
    "    print(\"Recall Score: {}\".format(recall_score(labels, preds, average=avg)))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(labels, preds)))\n",
    "    print(\"F1 Score: {}\".format(f1_score(labels, preds, average=avg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.9384829782998209\n",
      "Recall Score: 0.9384829782998209\n",
      "Accuracy Score: 0.9384829782998209\n",
      "F1 Score: 0.9384829782998209\n"
     ]
    }
   ],
   "source": [
    "print_knn_metrics(ptest, test_preds, 'micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(tf_idf_ptrain, ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1044735x1437 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2076465 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score: 0.9530161258212224\n",
      "Recall Score: 0.9530161258212224\n",
      "Accuracy Score: 0.9530161258212224\n",
      "F1 Score: 0.9530161258212224\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm_clf.predict(tf_idf_ptest)\n",
    "def print_svm_metrics(labels, preds, avg):\n",
    "    print(\"Precision Score: {}\".format(precision_score(labels, preds, average=avg)))\n",
    "    print(\"Recall Score: {}\".format(recall_score(labels, preds, average=avg)))\n",
    "    print(\"Accuracy Score: {}\".format(accuracy_score(labels, preds)))\n",
    "    print(\"F1 Score: {}\".format(f1_score(labels, preds, average=avg)))\n",
    "\n",
    "print_svm_metrics(ptest, svm_pred, 'micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
